from langgraph.graph import StateGraph, END
from langgraph.prebuilt import create_react_agent, ToolNode, MessagesState
from langchain_core.tools import tool, BaseTool
from langchain_core.messages import HumanMessage, AIMessage
from langchain.agents import AgentExecutor, create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain_openai import AzureChatOpenAI
from elasticsearch import Elasticsearch
from sqlalchemy import create_engine
import urllib.parse
import os
import json
from dotenv import load_dotenv
from typing import Annotated, Optional, Dict, List
from langgraph.types import Command
from langgraph.prebuilt import InjectedState, InjectedToolCallId
from pydantic import BaseModel, Field

# Load environment variables
load_dotenv()

# ========================
# 1. Configuration Setup
# ========================
class Config:
    def __init__(self):
        # Elasticsearch config
        self.elastic_index_data_from = 0
        self.elastic_index_data_size = 10
        self.elastic_index_data_max_size = 50
        self.aggs_limit = 5
        self.max_search_retries = 3
        self.token_limit = 3000
        
        # Initialize Elasticsearch
        self.es = Elasticsearch(
            os.getenv("ELASTIC_ENDPOINT"),
            api_key=os.getenv("ELASTIC_API_KEY"),
            verify_certs=False
        )
        
        # Initialize LLM
        self.llm = AzureChatOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            deployment_name="gpt-4",
            model="gpt-4",
            temperature=0
        )
        
        # SQL Server connection
        driver = '{ODBC Driver 18 for SQL Server}'
        server = os.getenv("SQL_SERVER")
        database = os.getenv("SQL_DATABASE")
        user = os.getenv("SQL_USER")
        password = os.getenv("SQL_PASSWORD")
        
        conn = f"Driver={driver};Server=tcp:{server},1433;Database={database};Uid={user};Pwd={password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;"
        params = urllib.parse.quote_plus(conn)
        conn_str = f'mssql+pyodbc:///?autocommit=true&odbc_connect={params}'
        self.engine = create_engine(conn_str)
        self.sql_db = SQLDatabase(self.engine)
        
        self.langchain_verbose = True

cfg = Config()

# ========================
# 2. Elasticsearch Tools
# ========================
class ListIndicesInput(BaseModel):
    separator: str = Field(", ", description="Separator for the list of indices")

class IndexDetailsInput(BaseModel):
    index_name: str = Field(..., description="Name of the Elasticsearch index")

class IndexDataInput(BaseModel):
    index_name: str = Field(..., description="Name of the Elasticsearch index")
    size: int = Field(5, description="Number of documents to retrieve")

class SearchToolInput(BaseModel):
    index_name: str = Field(..., description="Name of the Elasticsearch index")
    query: str = Field(..., description="Elasticsearch JSON query")
    from_: int = Field(0, description="Starting record index")
    size: int = Field(10, description="Number of records to retrieve")

@tool(args_schema=ListIndicesInput)
def list_indices(separator: str = ", ") -> str:
    """Lists all available Elasticsearch indices"""
    try:
        indices = list(cfg.es.indices.get(index="*").keys())
        return f"Available indices:{separator}{separator.join(indices)}"
    except Exception as e:
        return f"Error listing indices: {str(e)}"

@tool(args_schema=IndexDetailsInput)
def get_index_details(index_name: str) -> str:
    """Gets details about a specific index including mappings and settings"""
    try:
        if not cfg.es.indices.exists(index=index_name):
            return f"Index '{index_name}' does not exist"
        details = {
            "aliases": cfg.es.indices.get_alias(index=index_name).get(index_name, {}).get("aliases", {}),
            "mappings": cfg.es.indices.get_mapping(index=index_name).get(index_name, {}).get("mappings", {}),
            "settings": cfg.es.indices.get_settings(index=index_name).get(index_name, {}).get("settings", {})
        }
        return json.dumps(details, indent=2)
    except Exception as e:
        return f"Error getting index details: {str(e)}"

@tool(args_schema=IndexDataInput)
def get_index_data(index_name: str, size: int = 5) -> str:
    """Gets sample documents from an index to understand its structure"""
    try:
        if not cfg.es.indices.exists(index=index_name):
            return f"Index '{index_name}' does not exist"
        result = cfg.es.search(
            index=index_name,
            body={"query": {"match_all": {}}},
            size=min(size, cfg.elastic_index_data_max_size)
        )
        hits = result.get('hits', {}).get('hits', [])
        if not hits:
            return f"No documents found in index '{index_name}'"
        return json.dumps([hit['_source'] for hit in hits[:size]], indent=2)
    except Exception as e:
        return f"Error getting index data: {str(e)}"

@tool(args_schema=SearchToolInput)
def elastic_search(index_name: str, query: str, from_: int = 0, size: int = 10) -> str:
    """Executes a search or aggregation query on an Elasticsearch index"""
    try:
        if not cfg.es.indices.exists(index=index_name):
            return f"Index '{index_name}' does not exist"
        
        size = min(cfg.elastic_index_data_max_size, size)
        try:
            query_dict = json.loads(query)
        except json.JSONDecodeError:
            return "Invalid query format - must be valid JSON"

        # Determine if this is a search or aggregation
        is_aggregation = "aggs" in query_dict or "aggregations" in query_dict
        if is_aggregation:
            size = cfg.aggs_limit

        result = cfg.es.search(
            index=index_name,
            body=query_dict,
            from_=from_,
            size=size
        )

        if is_aggregation:
            return json.dumps(result.get('aggregations', {}), indent=2)
        else:
            return json.dumps(result.get('hits', {}), indent=2)
    except Exception as e:
        return f"Search error: {str(e)}"

elastic_tools = [list_indices, get_index_details, get_index_data, elastic_search]

# ========================
# 3. SQL Tools
# ========================
sql_toolkit = SQLDatabaseToolkit(db=cfg.sql_db, llm=cfg.llm)
sql_tools = sql_toolkit.get_tools()

# ========================
# 4. Agent Creation
# ========================
# Elasticsearch Agent
elastic_agent = create_react_agent(
    model=cfg.llm,
    tools=elastic_tools,
    prompt=(
        "You are an Elasticsearch expert.\n"
        "INSTRUCTIONS:\n"
        "- First list available indices with list_indices\n"
        "- Use get_index_details or get_index_data to understand structure\n"
        "- Use elastic_search for complex queries\n"
        "- Return ONLY the results, no extra text."
    ),
    name="elastic_agent"
)

# SQL Agent
sql_agent = create_sql_agent(
    llm=cfg.llm,
    toolkit=sql_toolkit,
    verbose=cfg.langchain_verbose,
    handle_parsing_errors=True,
    agent_type="openai-tools"
)

# ========================
# 5. Supervisor System
# ========================
def create_handoff_tool(agent_name: str, description: str | None = None):
    name = f"transfer_to_{agent_name}"
    description = description or f"Ask {agent_name} for help."

    @tool(name, description=description)
    def handoff_tool(
        state: Annotated[MessagesState, InjectedState],
        tool_call_id: Annotated[str, InjectedToolCallId],
    ) -> Command:
        tool_message = {
            "role": "tool",
            "content": f"Successfully transferred to {agent_name}",
            "name": name,
            "tool_call_id": tool_call_id,
        }
        return Command(
            goto=agent_name,
            update={**state, "messages": state["messages"] + [tool_message]},
            graph=Command.PARENT,
        )
    return handoff_tool

# Supervisor Tools
assign_to_elastic = create_handoff_tool(
    agent_name="elastic_agent",
    description="Assign task to Elasticsearch expert."
)

assign_to_sql = create_handoff_tool(
    agent_name="sql_agent",
    description="Assign task to SQL database expert."
)

# Supervisor Agent
supervisor_agent = create_react_agent(
    model=cfg.llm,
    tools=[assign_to_elastic, assign_to_sql],
    prompt=(
        "You are a supervisor managing two experts:\n"
        "- Elasticsearch agent: For NoSQL data queries\n"
        "- SQL agent: For relational database queries\n"
        "Analyze the request and delegate to the appropriate agent.\n"
        "Do not attempt to answer queries yourself."
    ),
    name="supervisor"
)

# ========================
# 6. Multi-Agent Graph
# ========================
workflow = StateGraph(MessagesState)
workflow.add_node("supervisor", supervisor_agent)
workflow.add_node("elastic_agent", elastic_agent)
workflow.add_node("sql_agent", sql_agent)

# Define edges
workflow.add_edge(START, "supervisor")
workflow.add_edge("elastic_agent", "supervisor")
workflow.add_edge("sql_agent", "supervisor")
workflow.add_conditional_edges(
    "supervisor",
    lambda x: END if "messages" in x and len(x["messages"]) > 5 else "supervisor"
)

# Compile
app = workflow.compile()

# ========================
# 7. Execution Example
# ========================
def run_query(query: str):
    response = app.invoke({
        "messages": [HumanMessage(content=query)]
    })
    
    print("\n=== FINAL RESPONSE ===")
    for msg in response["messages"]:
        if msg["role"] in ["user", "assistant"]:
            print(f"{msg['role'].upper()}: {msg['content']}")

# Example queries
run_query("Get total sales from SQL database and top 5 products from Elasticsearch")
run_query("Show me the schema of the SQL database and list all Elasticsearch indices")
