from langgraph.prebuilt import create_react_agent
from langgraph_supervisor import create_supervisor
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain_openai import AzureChatOpenAI
from elasticsearch import Elasticsearch
from sqlalchemy import create_engine
import urllib.parse
import os
import json
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain_core.tools import tool
from IPython.display import display, Image

# Load environment variables
load_dotenv()

# ========================
# 1. Configuration Setup (EXACTLY as you specified)
# ========================
class Config:
    def __init__(self):
        # Elasticsearch config
        self.elastic_index_data_from = 0
        self.elastic_index_data_size = 10
        self.elastic_index_data_max_size = 50
        self.aggs_limit = 5
        self.max_search_retries = 3
        self.token_limit = 3000
        
        # Initialize Elasticsearch
        self.es = Elasticsearch(
            os.getenv("ELASTIC_ENDPOINT"),
            api_key=os.getenv("ELASTIC_API_KEY"),
            verify_certs=False
        )
        
        # Initialize Azure OpenAI
        self.llm = AzureChatOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            deployment_name="gpt-4",
            model="gpt-4",
            temperature=0
        )
        
        # SQL Server connection
        driver = '{ODBC Driver 18 for SQL Server}'
        server = os.getenv("SQL_SERVER")
        database = os.getenv("SQL_DATABASE")
        user = os.getenv("SQL_USER")
        password = os.getenv("SQL_PASSWORD")
        
        conn = f"Driver={driver};Server=tcp:{server},1433;Database={database};Uid={user};Pwd={password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;"
        params = urllib.parse.quote_plus(conn)
        conn_str = f'mssql+pyodbc:///?autocommit=true&odbc_connect={params}'
        self.engine = create_engine(conn_str)
        self.sql_db = SQLDatabase(self.engine)
        
        self.langchain_verbose = True

cfg = Config()

# ========================
# 2. Elasticsearch Tools (COMPLETE implementation)
# ========================
class ListIndicesInput(BaseModel):
    separator: str = Field(", ", description="Separator for the list of indices")

class IndexDetailsInput(BaseModel):
    index_name: str = Field(..., description="Name of the Elasticsearch index")

class IndexDataInput(BaseModel):
    index_name: str = Field(..., description="Name of the Elasticsearch index")
    size: int = Field(5, description="Number of documents to retrieve")

class SearchToolInput(BaseModel):
    index_name: str = Field(..., description="Name of the Elasticsearch index")
    query: str = Field(..., description="Elasticsearch JSON query")
    from_: int = Field(0, description="Starting record index")
    size: int = Field(10, description="Number of records to retrieve")

@tool(args_schema=ListIndicesInput)
def list_indices(separator: str = ", ") -> str:
    """Lists all available Elasticsearch indices"""
    try:
        indices = list(cfg.es.indices.get(index="*").keys())
        return f"Available indices:{separator}{separator.join(indices)}"
    except Exception as e:
        return f"Error listing indices: {str(e)}"

@tool(args_schema=IndexDetailsInput)
def get_index_details(index_name: str) -> str:
    """Gets details about a specific index including mappings and settings"""
    try:
        if not cfg.es.indices.exists(index=index_name):
            return f"Index '{index_name}' does not exist"
        details = {
            "aliases": cfg.es.indices.get_alias(index=index_name).get(index_name, {}).get("aliases", {}),
            "mappings": cfg.es.indices.get_mapping(index=index_name).get(index_name, {}).get("mappings", {}),
            "settings": cfg.es.indices.get_settings(index=index_name).get(index_name, {}).get("settings", {})
        }
        return json.dumps(details, indent=2)
    except Exception as e:
        return f"Error getting index details: {str(e)}"

@tool(args_schema=IndexDataInput)
def get_index_data(index_name: str, size: int = 5) -> str:
    """Gets sample documents from an index to understand its structure"""
    try:
        if not cfg.es.indices.exists(index=index_name):
            return f"Index '{index_name}' does not exist"
        result = cfg.es.search(
            index=index_name,
            body={"query": {"match_all": {}}},
            size=min(size, cfg.elastic_index_data_max_size)
        )
        hits = result.get('hits', {}).get('hits', [])
        if not hits:
            return f"No documents found in index '{index_name}'"
        return json.dumps([hit['_source'] for hit in hits[:size]], indent=2)
    except Exception as e:
        return f"Error getting index data: {str(e)}"

@tool(args_schema=SearchToolInput)
def elastic_search(index_name: str, query: str, from_: int = 0, size: int = 10) -> str:
    """Executes a search or aggregation query on an Elasticsearch index"""
    try:
        if not cfg.es.indices.exists(index=index_name):
            return f"Index '{index_name}' does not exist"
        size = min(cfg.elastic_index_data_max_size, size)
        try:
            query_dict = json.loads(query)
        except json.JSONDecodeError:
            return "Invalid query format - must be valid JSON"

        is_aggregation = "aggs" in query_dict or "aggregations" in query_dict
        if is_aggregation:
            size = cfg.aggs_limit

        result = cfg.es.search(
            index=index_name,
            body=query_dict,
            from_=from_,
            size=size
        )

        if is_aggregation:
            return json.dumps(result.get('aggregations', {}), indent=2)
        else:
            return json.dumps(result.get('hits', {}), indent=2)
    except Exception as e:
        return f"Search error: {str(e)}"

elastic_tools = [list_indices, get_index_details, get_index_data, elastic_search]

# ========================
# 3. Create Agents (Following Research/Math Supervisor Pattern)
# ========================
# Elasticsearch Agent
elastic_agent = create_react_agent(
    model=cfg.llm,  # Using your Azure OpenAI instance
    tools=elastic_tools,
    prompt=(
        "You are an Elasticsearch expert agent.\n\n"
        "INSTRUCTIONS:\n"
        "- First list available indices with list_indices\n"
        "- Use get_index_details or get_index_data to understand structure\n"
        "- Use elastic_search for complex queries\n"
        "- Return ONLY the results, no extra text"
    ),
    name="elastic_agent"
)

# SQL Agent
sql_agent = create_sql_agent(
    llm=cfg.llm,  # Using your Azure OpenAI instance
    toolkit=SQLDatabaseToolkit(db=cfg.sql_db, llm=cfg.llm),
    verbose=cfg.langchain_verbose,
    handle_parsing_errors=True,
    agent_type="openai-tools",
    name="sql_agent"
)

# ========================
# 4. Supervisor Setup (Identical to Research/Math Example)
# ========================
supervisor = create_supervisor(
    model=cfg.llm,  # Using your Azure OpenAI instance
    agents=[elastic_agent, sql_agent],
    prompt=(
        "You are a supervisor managing:\n"
        "- elastic_agent: For Elasticsearch operations\n"
        "- sql_agent: For SQL database queries\n"
        "Assign tasks based on these rules:\n"
        "1. Data search/index operations → elastic_agent\n"
        "2. Database queries → sql_agent\n"
        "Assign one task at a time and wait for completion."
    ),
    add_handoff_back_messages=True,
    output_mode="full_history"
).compile()

# Display workflow
display(Image(supervisor.get_graph().draw_mermaid_png()))

# ========================
# 5. Execution Example
# ========================
def run_query(query: str):
    print(f"\n=== Processing: {query} ===")
    for chunk in supervisor.stream(
        {
            "messages": [
                {
                    "role": "user",
                    "content": query
                }
            ]
        }
    ):
        # Implement your message printing logic here
        print(chunk)

# Example queries
run_query("List all indices and count records in SQL customers table")
run_query("Get index details for 'products' and show 5 sample SQL orders")
