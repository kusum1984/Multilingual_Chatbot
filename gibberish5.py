import os
from dotenv import load_dotenv
from openai import AzureOpenAI
from typing import Tuple
import langdetect
from langdetect import DetectorFactory

# For consistent language detection
DetectorFactory.seed = 0

# Load environment variables
load_dotenv()

def get_client():
    return AzureOpenAI(
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_version="2023-07-01-preview"
    )

def check_gibberish(text: str) -> Tuple[str, str, str]:
    """
    Ultimate gibberish detector with example-based learning
    
    Returns:
        Tuple: (status, error_type, message)
        - status: 'T' (valid) or 'F' (invalid)
        - error_type: '' or 'gibberish_error'
        - message: Detailed explanation if invalid
    """
    # Comprehensive example-based prompt
    system_prompt = """
    # Ultimate Gibberish Detection System v2.0
    
    ## Your Task:
    Analyze text for meaningful content in ANY language using these guidelines:
    
    === VALID TEXT EXAMPLES ===
    1. Dictionary Words:
       - English: "apple", "computer"
       - Japanese: "„Åì„Çì„Å´„Å°„ÅØ" (hello)
       - Arabic: "ŸÉÿ™ÿßÿ®" (book)
    2. Proper Nouns:
       - "New York"
       - "Êù±‰∫¨„Çø„ÉØ„Éº" (Tokyo Tower)
       - "‡§Æ‡•Å‡§Ç‡§¨‡§à" (Mumbai)
    3. Technical Codes:
       - "ID-5849-BN"
       - "ËÆ¢ÂçïÂè∑: 456789" (Chinese order number)
    4. Common Phrases:
       - "How are you?"
       - "O√π est la gare?" (French: Where is the station?)
    5. Meaningful Single Characters:
       - "A" (grade)
       - "Êàë" (Chinese "I")
    
    === GIBBERISH EXAMPLES ===
    1. Random Typing:
       - "asdfjkl;"
       - "qwertyuiop"
    2. Impossible Combinations:
       - "xzqywv" (invalid English)
       - "Êº¢Â≠óÊº¢Â≠ó" (meaningless repetition)
    3. Nonsense Mixing:
       - "blah123blah"
       - "foo@bar$"
    4. Orthography Violations:
       - "Thsi is nto Enlgish"
       - "‡§ï‡§ñ‡§ó‡§ò" (invalid Devanagari)
    5. Meaningless Repetition:
       - "asdf asdf asdf"
       - "123 123 123"
    
    === DECISION RULES ===
    ‚úÖ VALID if any:
    - Real dictionary word
    - Recognizable name/entity
    - Valid code/number pattern
    - Culturally significant
    - Proper single character
    
    ‚ùå GIBBERISH if all:
    - No dictionary words
    - Violates language rules
    - Random character mixing
    - Meaningless repetition
    
    === RESPONSE FORMAT ===
    STRICTLY respond with ONLY:
    - "Valid" OR
    - "Invalid|<reason>|<detected_lang>"
      Where <reason> is:
      - random_characters
      - impossible_combinations
      - nonsense_repetition
      - no_meaningful_units
      - mixed_scripts
    """

    client = get_client()
    
    try:
        if not text.strip():
            return ("T", "", "")
            
        # First detect language
        try:
            lang = langdetect.detect(text)
        except:
            lang = "unknown"
        
        # Create user prompt with contextual examples
        user_prompt = f"""
        Analyze: "{text}"
        Initial language detection: {lang}
        
        Compare against these examples:
        [Valid] "Paris", "123 Main St", "ÏïàÎÖï", "@username"
        [Gibberish] "xjdkl", "asdf1234", "!@#$%^", "‡§ï‡§ñ‡§ó‡§ò"
        
        Your analysis (Valid/Invalid|Reason|Language):"""
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.0,
            max_tokens=100
        )

        result = response.choices[0].message.content.strip()
        
        if result == "Valid":
            return ("T", "", "")
        else:
            parts = result.split('|')
            reason = parts[1] if len(parts) > 1 else 'gibberish'
            detected_lang = parts[2] if len(parts) > 2 else lang
            
            return (
                "F",
                "gibberish_error",
                f"Gibberish detected: {reason} in {detected_lang}"
            )
            
    except Exception as e:
        return ("F", "api_error", f"Analysis failed: {str(e)}")


# ===== Comprehensive Test Suite (50+ Cases) =====
def run_tests():
    test_cases = [
        # Section 1: Valid Texts (25 cases)
        ("Hello world", "EN", "T"),
        ("Bonjour le monde", "FR", "T"),
        ("Hola mundo", "ES", "T"),
        ("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä", "RU", "T"),
        ("ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖ", "AR", "T"),
        ("‰Ω†Â•Ω‰∏ñÁïå", "ZH", "T"),
        ("„Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå", "JA", "T"),
        ("ÏïàÎÖïÌïòÏÑ∏Ïöî ÏÑ∏Í≥Ñ", "KO", "T"),
        ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ä‡∏≤‡∏ß‡πÇ‡∏•‡∏Å", "TH", "T"),
        ("Xin ch√†o th·∫ø gi·ªõi", "VI", "T"),
        ("Hallo Welt", "DE", "T"),
        ("Ciao mondo", "IT", "T"),
        ("Ol√° mundo", "PT", "T"),
        ("Witaj ≈õwiecie", "PL", "T"),
        ("ŒìŒµŒπŒ¨ œÉŒøœÖ ŒöœåœÉŒºŒµ", "EL", "T"),
        ("Merhaba d√ºnya", "TR", "T"),
        ("Hej v√§rlden", "SV", "T"),
        ("Pozdrav svijete", "HR", "T"),
        ("Ahoj svƒõte", "CS", "T"),
        ("Hell√≥ vil√°g", "HU", "T"),
        ("‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ", "HI", "T"),
        ("‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨", "BN", "T"),
        ("‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æâ‡Æ≤‡Æï‡ÆÆ‡Øç", "TA", "T"),
        ("◊©◊ú◊ï◊ù ◊¢◊ï◊ú◊ù", "HE", "T"),
        ("ID-5849-BN", "EN", "T"),
        
        # Section 2: Gibberish Cases (25 cases)
        ("asdfghjkl", "XX", "F"),
        ("qwertyuiop", "XX", "F"),
        ("–π—Ü—É–∫–µ–Ω–≥—à—â–∑", "XX", "F"),
        ("ÿ∂ÿµÿ´ŸÇÿ∂ÿµÿ´ŸÇ", "XX", "F"),
        ("„ÖÅ„Ñ¥„Öá„Ñπ„ÖÅ„Ñ¥„Öá", "XX", "F"),
        ("‡∏ü‡∏´‡∏Å‡∏î‡πà‡∏≤‡∏™‡∏ß", "XX", "F"),
        ("Œ±Œ≤Œ≥Œ¥Œ±Œ≤Œ≥Œ¥", "XX", "F"),
        ("◊ê◊ë◊í◊ì◊ê◊ë◊í◊ì", "XX", "F"),
        ("!@#$%^&*", "XX", "F"),
        ("xjdkl 392 sdk", "XX", "F"),
        ("xzqy wvut", "XX", "F"),
        ("blah blah", "XX", "F"),
        ("‡§ï‡•á‡§æ‡•Ä‡•Ä", "XX", "F"),
        ("asdf asdf asdf", "XX", "F"),
        ("123 123 123", "XX", "F"),
        ("foo@bar$", "XX", "F"),
        ("Êº¢Â≠óÊº¢Â≠ó", "XX", "F"),
        ("‡§ï‡§ñ‡§ó‡§ò", "XX", "F"),
        ("zzxxyy", "XX", "F"),
        ("qwopasdf", "XX", "F"),
        ("1a2b3c4d", "XX", "F"),
        ("asdf1234", "XX", "F"),
        ("@#$%^&", "XX", "F"),
        ("zxcvbnm", "XX", "F"),
        ("asdf;lkj", "XX", "F"),
        
        # Section 3: Edge Cases (10 cases)
        ("A", "EN", "T"),
        ("Êàë", "ZH", "T"),
        ("123", "EN", "T"),
        (" ", "XX", "T"),
        ("@username", "EN", "T"),
        ("#hashtag", "EN", "T"),
        ("ËÆ¢ÂçïÂè∑: 456789", "ZH", "T"),
        ("Êù±‰∫¨„Çø„ÉØ„Éº", "JA", "T"),
        ("asdf", "XX", "F"),
        ("‡§ï‡§ñ‡§ó", "XX", "F")
    ]

    print("=== Ultimate Gibberish Detection Test ===")
    print(f"Running {len(test_cases)} test cases across multiple languages\n")
    
    passed = 0
    for idx, (text, lang, expected) in enumerate(test_cases, 1):
        status, err_type, msg = check_gibberish(text)
        result = "‚úÖ PASS" if status == expected else "‚ùå FAIL"
        if status == expected:
            passed += 1
            
        print(f"{idx:02d} {result} {lang}: '{text[:20]}'")
        if status != expected:
            print(f"   Expected {expected}, got {status} | {msg}")
    
    accuracy = passed / len(test_cases) * 100
    print(f"\nResults: {passed}/{len(test_cases)} passed ({accuracy:.1f}% accuracy)")

if __name__ == "__main__":
    run_tests()

    ************************************
    # ===== Enhanced Test Suite with Language Detection Validation =====
def run_tests():
    test_cases = [
        # Format: (text, expected_status, expected_lang_if_valid)
        # Valid Texts
        ("Hello world", "T", "en"),
        ("Bonjour le monde", "T", "fr"),
        ("Hola mundo", "T", "es"),
        ("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä", "T", "ru"),
        ("ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖ", "T", "ar"),
        
        # Gibberish Cases (lang detection may fail)
        ("asdfghjkl", "F", None),
        ("qwertyuiop", "F", None),
        ("!@#$%^&*", "F", None),
        
        # Edge Cases
        ("123 Main St", "T", "en"),
        ("ID-5849-BN", "T", None),  # Codes often don't detect language
        ("@username", "T", None)    # Handles don't detect language
    ]

    print("=== Enhanced Gibberish Detection Test ===")
    print("Now validating both classification AND language detection\n")
    
    passed_classification = 0
    passed_language = 0
    total = len(test_cases)
    
    for idx, (text, expected_status, expected_lang) in enumerate(test_cases, 1):
        # Run detection
        status, err_type, msg = check_gibberish(text)
        
        # Get detected language
        try:
            detected_lang = langdetect.detect(text) if text.strip() else None
        except:
            detected_lang = None
        
        # Check classification
        classification_ok = status == expected_status
        if classification_ok:
            passed_classification += 1
            
        # Check language detection (only for valid texts)
        language_ok = True
        if expected_status == "T" and expected_lang:
            language_ok = detected_lang == expected_lang
            if language_ok:
                passed_language += 1
        
        # Print results
        result = []
        if classification_ok:
            result.append("‚úÖ CLASS")
        else:
            result.append("‚ùå CLASS")
            
        if not expected_lang or language_ok:
            result.append("‚úÖ LANG")
        else:
            result.append("‚ùå LANG")
        
        print(f"{idx:02d} {' '.join(result)}: '{text[:20]}'")
        print(f"   Status: {status} (expected {expected_status})")
        if expected_lang:
            print(f"   Language: {detected_lang} (expected {expected_lang})")
    
    # Calculate accuracy
    classification_acc = passed_classification / total * 100
    language_acc = passed_language / sum(1 for case in test_cases if case[2]) * 100
    
    print(f"\nResults:")
    print(f"- Classification: {passed_classification}/{total} ({classification_acc:.1f}%)")
    print(f"- Language Detection: {passed_language}/{sum(1 for case in test_cases if case[2])} ({language_acc:.1f}%)")

if __name__ == "__main__":
    run_tests()
***********************************************
# ===== Comprehensive Test Suite (100+ Cases) =====
def run_tests():
    test_cases = [
        # Section 1: Indo-European Languages (30 cases)
        ("Hello world", "T", "en"),  # English
        ("Bonjour le monde", "T", "fr"),  # French
        ("Hola mundo", "T", "es"),  # Spanish
        ("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä", "T", "ru"),  # Russian
        ("‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ", "T", "hi"),  # Hindi
        ("ŒìŒµŒπŒ¨ œÉŒøœÖ ŒöœåœÉŒºŒµ", "T", "el"),  # Greek
        ("Witaj ≈õwiecie", "T", "pl"),  # Polish
        ("Hej v√§rlden", "T", "sv"),  # Swedish
        ("Hall√≥ heimur", "T", "is"),  # Icelandic
        ("Sveika pasaule", "T", "lv"),  # Latvian
        ("P√´rsh√´ndetje bot√´", "T", "sq"),  # Albanian
        ("Salve mundi", "T", "la"),  # Latin
        ("Dia duit domhan", "T", "ga"),  # Irish
        ("Helo byd", "T", "cy"),  # Welsh
        ("Salam dunia", "T", "ms"),  # Malay
        ("‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞ ‡¨¨‡¨ø‡¨∂‡≠ç‡≠±", "T", "or"),  # Odia
        ("‡®∏‡®§‡®ø ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤ ‡®¶‡©Å‡®®‡®ø‡®Ü", "T", "pa"),  # Punjabi
        ("‡™π‡´á‡™≤‡´ã ‡™µ‡™∞‡´ç‡™≤‡´ç‡™°", "T", "gu"),  # Gujarati
        ("‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨", "T", "bn"),  # Bengali
        ("‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æâ‡Æ≤‡Æï‡ÆÆ‡Øç", "T", "ta"),  # Tamil
        ("‡∞π‡∞≤‡±ã ‡∞™‡±ç‡∞∞‡∞™‡∞Ç‡∞ö‡∞Ç", "T", "te"),  # Telugu
        ("‡¥π‡¥≤‡µã ‡¥µ‡µá‡µæ‡¥°‡µç", "T", "ml"),  # Malayalam
        ("‡®∏‡®§‡®ø ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤ ‡®¶‡©Å‡®®‡®ø‡®Ü", "T", "pa"),  # Punjabi
        ("ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖ", "T", "ar"),  # Arabic
        ("◊©◊ú◊ï◊ù ◊¢◊ï◊ú◊ù", "T", "he"),  # Hebrew
        ("ÿ≥ŸÑÿßŸÖ ÿØŸÜ€åÿß", "T", "fa"),  # Persian
        ("‡§π‡•Ö‡§≤‡•ã ‡§µ‡§∞‡•ç‡§≤‡•ç‡§°", "T", "mr"),  # Marathi
        ("‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§∞", "T", "ne"),  # Nepali
        ("‡∑Ñ‡∑ô‡∂Ω‡∑ù ‡∑Ä‡∂ª‡∑ä‡∂Ω‡∑ä‡∂©‡∑ä", "T", "si"),  # Sinhala
        ("·ûá·üÜ·ûö·û∂·ûî·ûü·ûΩ·ûö ·ûñ·û∑·ûó·ûñ·ûõ·üÑ·ûÄ", "T", "km"),  # Khmer
        
        # Section 2: Asian Languages (25 cases)
        ("‰Ω†Â•Ω‰∏ñÁïå", "T", "zh"),  # Chinese
        ("„Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå", "T", "ja"),  # Japanese
        ("ÏïàÎÖïÌïòÏÑ∏Ïöî ÏÑ∏Í≥Ñ", "T", "ko"),  # Korean
        ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ä‡∏≤‡∏ß‡πÇ‡∏•‡∏Å", "T", "th"),  # Thai
        ("Xin ch√†o th·∫ø gi·ªõi", "T", "vi"),  # Vietnamese
        ("·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´·ÄÄ·Äô·Äπ·Äò·Ä¨·Äú·Ä±·Ä¨·ÄÄ", "T", "my"),  # Burmese
        ("‡∑Ñ‡∑ô‡∂Ω‡∑ù ‡∑Ä‡∂ª‡∑ä‡∂Ω‡∑ä‡∂©‡∑ä", "T", "si"),  # Sinhala
        ("·ûü·ûΩ·ûü·üí·ûè·û∏·ûñ·û∑·ûó·ûñ·ûõ·üÑ·ûÄ", "T", "km"),  # Khmer
        ("·Äô·ÄÑ·Ä∫·Äπ·ÄÇ·Äú·Ä¨·Äï·Ä´", "T", "my"),  # Burmese
        ("‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ‡∫ä‡∫≤‡∫ß‡ªÇ‡∫•‡∫Å", "T", "lo"),  # Lao
        ("·†∞·††·†¢·†® ·†™·††·†¢·†®·††·†∑ ·†≥·†ã·†§·†≠·††·†∑", "T", "mn"),  # Mongolian
        ("‡ΩÇ‡æ≤‡Ωº‡Ω¶‡ºã‡Ωö‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω†‡Ωõ‡Ω≤‡Ωì‡ºã‡Ω¶‡æê‡æ±‡Ωº‡ΩÑ‡ºã", "T", "bo"),  # Tibetan
        ("‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞ ‡¨¨‡¨ø‡¨∂‡≠ç‡≠±", "T", "or"),  # Odia
        ("‡®π‡©à‡®≤‡©ã ‡®µ‡®∞‡®≤‡®°", "T", "pa"),  # Punjabi
        ("‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨", "T", "bn"),  # Bengali
        ("‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æâ‡Æ≤‡Æï‡ÆÆ‡Øç", "T", "ta"),  # Tamil
        ("‡∞π‡∞≤‡±ã ‡∞™‡±ç‡∞∞‡∞™‡∞Ç‡∞ö‡∞Ç", "T", "te"),  # Telugu
        ("‡¥π‡¥≤‡µã ‡¥µ‡µá‡µæ‡¥°‡µç", "T", "ml"),  # Malayalam
        ("‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞", "T", "or"),  # Odia
        ("‡®∏‡®§‡®ø ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤", "T", "pa"),  # Punjabi
        ("‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã", "T", "bn"),  # Bengali
        ("‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç", "T", "ta"),  # Tamil
        ("‡∞π‡∞≤‡±ã", "T", "te"),  # Telugu
        ("‡¥π‡¥≤‡µã", "T", "ml"),  # Malayalam
        ("„Åì„Çì„Å´„Å°„ÅØ", "T", "ja"),  # Japanese
        
        # Section 3: African Languages (15 cases)
        ("Sawubona Mhlaba", "T", "zu"),  # Zulu
        ("Habari dunia", "T", "sw"),  # Swahili
        ("Dumela lefatshe", "T", "tn"),  # Tswana
        ("Moni m'dziko", "T", "ny"),  # Chichewa
        ("Sannu duniya", "T", "ha"),  # Hausa
        ("Ndewo ·ª•wa", "T", "ig"),  # Igbo
        ("Salamu dunia", "T", "am"),  # Amharic
        ("Mo ki O Ile Aiye", "T", "yo"),  # Yoruba
        ("Agoo dunia", "T", "ee"),  # Ewe
        ("Kedu uwa", "T", "ig"),  # Igbo
        ("Sanu duniyan", "T", "ff"),  # Fulani
        ("Akwaba wiase", "T", "ak"),  # Akan
        ("Mwaramutse isi", "T", "rw"),  # Kinyarwanda
        ("Saluton mondo", "T", "eo"),  # Esperanto (not African but included)
        ("Hallo w√™reld", "T", "af"),  # Afrikaans
        
        # Section 4: Indigenous/Endangered Languages (10 cases)
        ("Kwe kwe otsi", "T", "cr"),  # Cree
        ("H√°u mit√°kuye oy√°s'i≈ã", "T", "lkt"),  # Lakota
        ("Y√°'√°t'√©√©h", "T", "nv"),  # Navajo
        ("Aloha honua", "T", "haw"),  # Hawaiian
        ("Kia ora te ao", "T", "mi"),  # MƒÅori
        ("Ahalan dunia", "T", "ber"),  # Berber
        ("Bozo aylan", "T", "ber"),  # Berber
        ("Kamusta mundo", "T", "fil"),  # Filipino
        ("Halo dunia", "T", "id"),  # Indonesian
        ("Talofa lalolagi", "T", "sm"),  # Samoan
        
        # Section 5: Gibberish Cases (20 cases)
        ("asdfghjkl", "F", None),
        ("qwertyuiop", "F", None),
        ("–π—Ü—É–∫–µ–Ω–≥—à—â–∑", "F", None),
        ("ÿ∂ÿµÿ´ŸÇÿ∂ÿµÿ´ŸÇ", "F", None),
        ("„ÖÅ„Ñ¥„Öá„Ñπ„ÖÅ„Ñ¥„Öá", "F", None),
        ("‡∏ü‡∏´‡∏Å‡∏î‡πà‡∏≤‡∏™‡∏ß", "F", None),
        ("Œ±Œ≤Œ≥Œ¥Œ±Œ≤Œ≥Œ¥", "F", None),
        ("◊ê◊ë◊í◊ì◊ê◊ë◊í◊ì", "F", None),
        ("!@#$%^&*", "F", None),
        ("xjdkl 392 sdk", "F", None),
        ("xzqy wvut", "F", None),
        ("blah blah", "F", None),
        ("‡§ï‡•á‡§æ‡•Ä‡•Ä", "F", None),
        ("asdf asdf asdf", "F", None),
        ("123 123 123", "F", None),
        ("foo@bar$", "F", None),
        ("Êº¢Â≠óÊº¢Â≠ó", "F", None),
        ("‡§ï‡§ñ‡§ó‡§ò", "F", None),
        ("zzxxyy", "F", None),
        ("qwopasdf", "F", None),
        
        # Section 6: Edge Cases (10 cases)
        ("A", "T", None),  # Single character
        ("Êàë", "T", "zh"),  # Chinese character
        ("123", "T", None),  # Numbers
        (" ", "T", None),  # Empty string
        ("@username", "T", None),  # Handle
        ("#hashtag", "T", None),  # Tag
        ("ID-5849-BN", "T", None),  # Code
        ("Êù±‰∫¨„Çø„ÉØ„Éº", "T", "ja"),  # Mixed script
        ("asdf", "F", None),  # Short gibberish
        ("‡§ï‡§ñ‡§ó", "F", None)  # Invalid sequence
    ]

    print("=== Ultimate Language Validation Test ===")
    print(f"Running {len(test_cases)} test cases across 50+ languages\n")
    
    passed_classification = 0
    passed_language = 0
    total = len(test_cases)
    lang_expected_count = sum(1 for case in test_cases if case[2])
    
    for idx, (text, expected_status, expected_lang) in enumerate(test_cases, 1):
        # Run detection
        status, err_type, msg = check_gibberish(text)
        
        # Get detected language
        try:
            detected_lang = langdetect.detect(text) if text.strip() and expected_status == "T" else None
        except:
            detected_lang = None
        
        # Check classification
        classification_ok = status == expected_status
        if classification_ok:
            passed_classification += 1
            
        # Check language detection (only for valid texts with expected lang)
        language_ok = True
        if expected_status == "T" and expected_lang:
            language_ok = detected_lang == expected_lang
            if language_ok:
                passed_language += 1
        
        # Print results
        result = []
        if classification_ok:
            result.append("‚úÖ CLASS")
        else:
            result.append("‚ùå CLASS")
            
        if not expected_lang or language_ok:
            result.append("‚úÖ LANG")
        else:
            result.append(f"‚ùå LANG (got {detected_lang})")
        
        print(f"{idx:03d} {' '.join(result)}: '{text[:20]}'")
        if not classification_ok:
            print(f"   Expected {expected_status}, got {status} | {msg}")
    
    # Calculate accuracy
    classification_acc = passed_classification / total * 100
    language_acc = passed_language / lang_expected_count * 100 if lang_expected_count > 0 else 100
    
    print(f"\n=== Final Results ===")
    print(f"Classification Accuracy: {passed_classification}/{total} ({classification_acc:.1f}%)")
    print(f"Language Detection Accuracy: {passed_language}/{lang_expected_count} ({language_acc:.1f}%)")

if __name__ == "__main__":
    run_tests()



*********************************************************************************************************

import os
from dotenv import load_dotenv
from openai import AzureOpenAI
from typing import Tuple
import langdetect
from langdetect import DetectorFactory
import pandas as pd
from datetime import datetime

# For consistent language detection
DetectorFactory.seed = 0

# Load environment variables
load_dotenv()

def get_client():
    return AzureOpenAI(
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_version="2023-07-01-preview"
    )

def check_gibberish(text: str) -> Tuple[str, str, str]:
    """[Previous implementation remains exactly the same]"""
    # [Previous code here - unchanged]
    pass

def run_tests():
    test_cases = [
        # [Previous valid test cases remain the same]
        # ...
        
        # Enhanced Section 5: Gibberish Cases (50 cases now)
        # English-like gibberish
        ("asdfghjkl", "F", None),
        ("qwertyuiop", "F", None),
        ("zxcvbnm", "F", None),
        ("poiuytrewq", "F", None),
        ("lkjhgfdsa", "F", None),
        ("mnbvcxz", "F", None),
        ("asdf;lkj", "F", None),
        ("jfkdls;a", "F", None),
        
        # International keyboard gibberish
        ("–π—Ü—É–∫–µ–Ω–≥—à—â–∑", "F", None),  # Russian-like
        ("—Ñ—ã–≤–∞–ø—Ä–æ–ª–¥–∂—ç", "F", None),  # Russian-like
        ("asdf√±lkj", "F", None),  # Spanish-like
        ("√©√†√®√π√ß", "F", None),  # French-like
        ("√§√∂√º√ü", "F", None),  # German-like
        ("Œ±Œ≤Œ≥Œ¥ŒµŒ∂", "F", None),  # Greek-like
        ("◊ê◊ë◊í◊ì◊î◊ï◊ñ", "F", None),  # Hebrew-like
        ("ÿ∂ÿµÿ´ŸÇŸÅÿ∫", "F", None),  # Arabic-like
        ("„Ñ±„Ñ¥„Ñ∑„Ñπ„ÖÅ„ÖÇ", "F", None),  # Korean-like
        ("„ÅÇ„Åã„Åï„Åü„Å™„ÅØ", "F", None),  # Japanese-like
        
        # Mixed-script gibberish
        ("aŒ≤cŒ¥Œµf", "F", None),
        ("xÊº¢yÂ≠óz", "F", None),
        ("1„ÅÇ2„ÅÑ3„ÅÜ", "F", None),
        ("aŒ±bŒ≤cŒ≥", "F", None),
        ("@#¬¢‚àû¬ß√∑", "F", None),
        
        # Pattern-based gibberish
        ("abcabcabc", "F", None),
        ("123123123", "F", None),
        ("q1w2e3r4", "F", None),
        ("!a@b#c$", "F", None),
        ("a_b_c_d_", "F", None),
        
        # Common password-like gibberish
        ("password123", "F", None),
        ("qwerty123", "F", None),
        ("letmein", "F", None),
        ("adminadmin", "F", None),
        ("welcome1", "F", None),
        
        # Unicode abuse
        ("‚Ñ¶‚âà√ß‚àö‚à´Àú¬µ", "F", None),
        ("‚ÅÑ‚Ç¨‚Äπ‚Ä∫Ô¨ÅÔ¨Ç‚Ä°¬∞", "F", None),
        ("‚ìê‚ìë‚ìí‚ìì‚ìî", "F", None),
        ("·¥¨·¥Æ·∂ú·¥∞·¥±", "F", None),
        ("‚Çê‚Çë‚Çí‚Çì‚Çî", "F", None),
        
        # Emoji/non-text
        ("üòÄüòÉüòÑüòÅ", "F", None),
        ("üëçüëéüíØ", "F", None),
        ("üöÄüåï‚ú®", "F", None),
        ("üîëüóùÔ∏èüîí", "F", None),
        ("üì±üíªüñ•Ô∏è", "F", None),
        
        # [Previous edge cases remain the same]
        # ...
    ]

    print("=== Ultimate Gibberish Detection Test ===")
    print(f"Running {len(test_cases)} test cases across 50+ languages\n")
    
    # Prepare results dataframe
    results = []
    columns = [
        'Language', 
        'Word', 
        'Expected Status', 
        'Actual Status',
        'Classification Result',
        'Expected LangCode',
        'Detected LangCode',
        'Language Detection Result',
        'Error Message',
        'Timestamp'
    ]
    
    for idx, (text, expected_status, expected_lang) in enumerate(test_cases, 1):
        # Run detection
        status, err_type, msg = check_gibberish(text)
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Get detected language
        detected_lang = None
        lang_result = "N/A"
        if expected_status == "T" and text.strip():
            try:
                detected_lang = langdetect.detect(text)
                lang_result = "‚úÖ" if detected_lang == expected_lang else "‚ùå"
            except:
                detected_lang = "Detection Failed"
                lang_result = "‚ùå"
        
        # Build result row
        results.append([
            expected_lang if expected_lang else "Gibberish",
            text,
            expected_status,
            status,
            "‚úÖ" if status == expected_status else "‚ùå",
            expected_lang if expected_lang else "N/A",
            detected_lang if detected_lang else "N/A",
            lang_result,
            msg if status != expected_status else "",
            timestamp
        ])
        
        # Print progress
        print(f"{idx:03d} Tested: '{text[:20]}'")
    
    # Create DataFrame
    df = pd.DataFrame(results, columns=columns)
    
    # Save to Excel
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"gibberish_test_results_{timestamp}.xlsx"
    df.to_excel(filename, index=False)
    
    # Calculate statistics
    classification_acc = (df['Classification Result'] == '‚úÖ').mean() * 100
    lang_acc = (df['Language Detection Result'] == '‚úÖ').mean() * 100
    
    print(f"\n=== Final Results ===")
    print(f"Classification Accuracy: {classification_acc:.1f}%")
    print(f"Language Detection Accuracy: {lang_acc:.1f}%")
    print(f"Results saved to {filename}")

if __name__ == "__main__":
    run_tests()



*******************************************************************
import os
from dotenv import load_dotenv
from openai import AzureOpenAI
from typing import Tuple
import langdetect
from langdetect import DetectorFactory
import pandas as pd
from datetime import datetime

# For consistent language detection
DetectorFactory.seed = 0

# Language code to name mapping
LANGUAGE_NAMES = {
    'en': 'English',
    'fr': 'French',
    'es': 'Spanish',
    'ru': 'Russian',
    'ar': 'Arabic',
    'zh': 'Chinese',
    'ja': 'Japanese',
    'ko': 'Korean',
    'hi': 'Hindi',
    'bn': 'Bengali',
    'pa': 'Punjabi',
    'ta': 'Tamil',
    'te': 'Telugu',
    'mr': 'Marathi',
    'ur': 'Urdu',
    'gu': 'Gujarati',
    'kn': 'Kannada',
    'or': 'Odia',
    'ml': 'Malayalam',
    'de': 'German',
    'it': 'Italian',
    'pt': 'Portuguese',
    'pl': 'Polish',
    'tr': 'Turkish',
    'nl': 'Dutch',
    'sv': 'Swedish',
    'fi': 'Finnish',
    'da': 'Danish',
    'no': 'Norwegian',
    'he': 'Hebrew',
    'fa': 'Persian',
    'th': 'Thai',
    'vi': 'Vietnamese',
    'id': 'Indonesian',
    'ms': 'Malay',
    'fil': 'Filipino',
    'sw': 'Swahili',
    'ha': 'Hausa',
    'yo': 'Yoruba',
    'ig': 'Igbo',
    'zu': 'Zulu',
    'xh': 'Xhosa',
    'st': 'Sotho',
    'sn': 'Shona',
    'am': 'Amharic',
    'so': 'Somali',
    'haw': 'Hawaiian',
    'mi': 'MƒÅori',
    'sm': 'Samoan',
    'to': 'Tongan',
    'fj': 'Fijian',
    'el': 'Greek',
    'hu': 'Hungarian',
    'cs': 'Czech',
    'sk': 'Slovak',
    'hr': 'Croatian',
    'sr': 'Serbian',
    'sl': 'Slovenian',
    'bg': 'Bulgarian',
    'uk': 'Ukrainian',
    'be': 'Belarusian',
    'kk': 'Kazakh',
    'uz': 'Uzbek',
    'ky': 'Kyrgyz',
    'tg': 'Tajik',
    'mn': 'Mongolian',
    'bo': 'Tibetan',
    'ne': 'Nepali',
    'si': 'Sinhala',
    'km': 'Khmer',
    'lo': 'Lao',
    'my': 'Burmese',
    'ka': 'Georgian',
    'hy': 'Armenian',
    'az': 'Azerbaijani',
    'tk': 'Turkmen',
    'et': 'Estonian',
    'lv': 'Latvian',
    'lt': 'Lithuanian',
    'cy': 'Welsh',
    'ga': 'Irish',
    'gd': 'Scottish Gaelic',
    'mt': 'Maltese',
    'eu': 'Basque',
    'ca': 'Catalan',
    'gl': 'Galician',
    'af': 'Afrikaans',
    'is': 'Icelandic',
    'fo': 'Faroese',
    'sa': 'Sanskrit',
    'la': 'Latin',
    'eo': 'Esperanto'
}

def get_language_name(lang_code):
    """Convert language code to full name"""
    return LANGUAGE_NAMES.get(lang_code, lang_code) if lang_code else "Gibberish"

def get_client():
    return AzureOpenAI(
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_version="2023-07-01-preview"
    )

def check_gibberish(text: str) -> Tuple[str, str, str]:
    """[Previous implementation remains exactly the same]"""
    # [Previous code here - unchanged]
    pass

def run_tests():
    test_cases = [
        # [Your existing test cases remain exactly the same]
        # ...
    ]

    print("=== Ultimate Gibberish Detection Test ===")
    print(f"Running {len(test_cases)} test cases across 50+ languages\n")
    
    # Prepare results dataframe
    results = []
    columns = [
        'Language', 
        'Word', 
        'Expected Status', 
        'Actual Status',
        'Classification Result',
        'Expected LangCode',
        'Detected LangCode',
        'Language Detection Result',
        'Error Message',
        'Timestamp'
    ]
    
    for idx, (text, expected_status, expected_lang) in enumerate(test_cases, 1):
        # Run detection
        status, err_type, msg = check_gibberish(text)
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Get detected language
        detected_lang = None
        lang_result = "N/A"
        if expected_status == "T" and text.strip():
            try:
                detected_lang = langdetect.detect(text)
                lang_result = "‚úÖ" if detected_lang == expected_lang else "‚ùå"
            except:
                detected_lang = "Detection Failed"
                lang_result = "‚ùå"
        
        # Build result row with language names
        results.append([
            get_language_name(expected_lang) if expected_lang else "Gibberish",
            text,
            expected_status,
            status,
            "‚úÖ" if status == expected_status else "‚ùå",
            expected_lang if expected_lang else "N/A",
            detected_lang if detected_lang else "N/A",
            lang_result,
            msg if status != expected_status else "",
            timestamp
        ])
        
        # Print progress
        print(f"{idx:03d} Tested: '{text[:20]}'")
    
    # Create DataFrame
    df = pd.DataFrame(results, columns=columns)
    
    # Save to Excel
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"gibberish_test_results_{timestamp}.xlsx"
    df.to_excel(filename, index=False)
    
    # Calculate statistics
    classification_acc = (df['Classification Result'] == '‚úÖ').mean() * 100
    lang_acc = (df[df['Language Detection Result'] != 'N/A']['Language Detection Result'] == '‚úÖ').mean() * 100
    
    print(f"\n=== Final Results ===")
    print(f"Classification Accuracy: {classification_acc:.1f}%")
    print(f"Language Detection Accuracy: {lang_acc:.1f}%")
    print(f"Results saved to {filename}")

if __name__ == "__main__":
    run_tests()
